# ComfyUI RyanOnTheInside Node Pack

## Overview
RyanOnTheInside node pack introduces the following:
- Particle Systems - dynamic particle systems in Comfy!
- Audio Masks - Create reactive masks from audio! Even separate vocals, drums, bass, etc!
- Optical Flow - Masks generated by the motion in a video!
- Temporal Masks - Apply effects to masks over tiiiiime!

<table style="border-collapse: collapse; border: none;">
  <tr>
    <td style="border: none; padding: 0 2px 2px 0;"><img src="./assets/particle_systems.gif" width="300" alt="RyanOnTheInside particle demo header"></td>
    <td style="border: none; padding: 0 0 2px 2px;"><img src="./assets/optical_flow.gif" width="300" alt="RyanOnTheInside optical flow demo"></td>
  </tr>
  <tr>
    <td style="border: none; padding: 2px 2px 0 0;">
      <img src="./assets/time.gif" width="300" alt="Time"><br>
      <img src="./assets/plume_examples.gif" width="300" alt="Plume examples using two particle emitters" style="margin-top: 2px;">
    </td>
    <td style="border: none; padding: 2px 0 0 2px;"><img src="./assets/iris.gif" width="300" alt="Plume examples using two particle emitters"></td>
  </tr>
  <tr>
    <td colspan="2" style="border: none; padding: 2px 0 0 0;"><img src="./assets/earth.gif" width="600" alt="Earth particle collision"></td>
  </tr>
</table>

*Examples showcasing various effects using particle emitters, vortices, and other node features*
<!-- 
## Table of Contents
- [Installation](#installation)
- [Requirements](#requirements)
- [Features](#features)
  - [Particle System Masks](#particle-system-masks)
  - [Flex Masks](#flex-masks)
  - [Audio and MIDI Masks](#audio-and-midi-masks)
  - [Optical Flow Masks](#optical-flow-masks)
  - [Temporal Masks](#temporal-masks)
  - [Miscellaneous Nodes](#miscellaneous-nodes)
- [Contributing](#contributing)
- [License](#license)
- [Support](#support) -->

<details>
<summary><h2>Installation</h2></summary>

Install via the ComfyUI Manager by searching for RyanOnTheInside, or...

1. Navigate to your ComfyUI's `custom_nodes` directory
2. Clone the repository:
   ```
   git clone https://github.com/ryanontheinside/ComfyUI_RyanOnTheInside.git
   ```
3. Navigate to the cloned directory:
   ```
   cd ComfyUI_RyanOnTheInside
   ```
4. Install the required dependencies:
   ```
   pip install -r requirements.txt
   ```
5. Restart ComfyUI if it's currently running and refresh your browser

### Requirements

See `requirements.txt` for a list of dependencies.

</details>

## Features

<details>
<summary><h3>üéÜ Particle System Masks</h3></summary>

Create mesmerizing, fluid-like effects through advanced particle simulation. Bring your masks to life with dynamic, interactive elements.

- Multiple particle emitters with independent settings (spread, speed, size, color, etc.)
- Customizable force fields (Gravity Wells and Vortices) for complex particle interactions
- Adjustable global gravity and wind settings for each simulation space
- Boundary-respecting particles that interact with mask shapes
- Static bodies for intricate particle collisions and interactions
- Spring joint settings for creating interconnected particle systems
- Particle modulation over time (size, speed, color)

<img src="./assets/particle_examples.gif" width="400" alt="Particle System Demo showing various effects like object-aware particles, plume effects, and vortex interactions">

*Examples showcasing object-aware particles, initial plume effects, vortex interactions, gravity wells, and directional emitters.*

</details>

<details>
<summary><h3>üé® Flex Masks</h3></summary>

Create dynamic, feature-driven mask effects that adapt to various inputs such as time, audio, MIDI, or depth information.

- Modulate mask operations based on extracted features
- Apply morphological operations (erode, dilate, open, close) with feature-based intensity
- Create warping effects (perlin, radial, swirl) modulated by features
- Perform geometric transformations (translate, rotate, scale) driven by feature values
- Combine masks using mathematical operations with feature-based strength

Features can be extracted from:
- Time-based patterns (smooth, accelerate, pulse, sawtooth, bounce)
- Audio characteristics (amplitude, energy, spectral centroid, onset detection, chroma)
- MIDI data (note velocity, pitch, control changes)
- Depth information (mean depth, variance, range, gradient, foreground/midground/background ratios)

Example applications:
- Create masks that pulse with the beat of music
- Generate depth-aware mask effects that respond to scene geometry
- Produce complex animations driven by MIDI sequences
- Combine multiple features for intricate, multi-dimensional mask modulations

These flexible mask nodes allow for complex, adaptive effects that respond dynamically to various inputs, enabling unprecedented levels of creative control and expressiveness in mask generation.

</details>

<details>
<summary><h3>üéµ Audio and MIDI Masks</h3></summary>

Transform your masks with the power of sound and musical data. Create dynamic, audio-reactive effects that pulse and morph to the rhythm of your chosen audio or MIDI input.

Audio Features:
- Separate audio into individual tracks (vocals, drums, bass, other instruments)
- Apply audio-driven effects to masks based on various audio features
- Create complex audio visualizations and mask modulations
- Utilize frequency filtering for targeted audio processing
- Generate audio-reactive animations and transformations

MIDI Features:
- Extract features from MIDI files or real-time MIDI input
- Use note velocity, pitch, and control changes (expression, aftertouch, anything) to modulate mask properties
- Create rhythmic mask patterns based on MIDI note timing
- Apply complex mask transformations driven by MIDI sequences

These audio and MIDI processing nodes enable analysis, filtering, and feature extraction, allowing for creative audio-driven and musically-responsive effects and visualizations within the ComfyUI environment.

</details>

<details>
<summary><h3>üåä Optical Flow Masks</h3></summary>

Harness the power of motion to create stunning visual effects. Generate masks based on movement in video sequences for dynamic, flow-based animations.

- Choose from multiple optical flow algorithms (Farneback, Lucas-Kanade, Pyramidal Lucas-Kanade)
- Create particle simulations reactive to optical flow (work in progress)
- Isolate and emphasize directional flow for targeted effects (in progress)
- Apply advanced blending and modulation options for seamless integration

<img src="./assets/opticalflow_examples.gif" width="400" alt="Optical Flow Demo showing motion-generated trails and effects">

*Motion generated trails using optical flow analysis*

</details>

<details>
<summary><h3>‚è≥ Temporal Masks</h3></summary>

Add the dimension of time to your mask effects. Create evolving, dynamic animations that transform your masks over the course of your video.

- Apply time-based morphing and transformation effects (erosion, dilation, translation, rotation, scaling)
- Utilize various mask combination methods for complex temporal interactions
- Create radial and pulsating effects for eye-catching animations
- Generate warp effects using Perlin noise, radial distortion, and swirling patterns
- Customize with various easing functions and palindrome support for smooth transitions

<img src="./assets/temporal_examples.gif" width="400" alt="Temporal Masks Examples showing various time-based effects">

*Examples of various combinations of temporal mask effects including morphing, transformations, math, and warping.*

</details>

<details>
<summary><h3>üõ†Ô∏è Miscellaneous Nodes</h3></summary>

Enhance your mask creation toolkit with additional utility nodes for specific effects and animations.

- Generate masks and images with customizable text
- Create moving shape masks with adjustable parameters (size, position, color, movement type)
- Combine multiple mask types for unique, hybrid effects
- Apply advanced blending modes between different mask types
- Create custom mask patterns using mathematical functions

These versatile nodes allow for endless creativity in mask generation and manipulation, enabling you to achieve precise control over your visual effects.

</details>

## Contributing

Contributions are welcome! Both to the code and EXAMPLE WORKFLOWS!!! If you'd like to contribute:

1. Fork the repository
2. Create a new branch for your feature or bug fix
3. Make your changes and commit them with descriptive commit messages
4. Push your changes to your fork
5. Submit a pull request to the main repository

## License

This project is licensed under the Creative Commons Attribution-NonCommercial 4.0 International License (CC BY-NC 4.0).

You are free to share and adapt the material for non-commercial purposes, as long as you give appropriate credit and indicate if changes were made.

For more details, see the [full license text](https://creativecommons.org/licenses/by-nc/4.0/legalcode).

## Support

For issues, questions, or suggestions, please open an issue on the GitHub repository.
